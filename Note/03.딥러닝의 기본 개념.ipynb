{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 학습\n",
    "- 모델에 입력값을 넣었을때 출력값이 최대한 정답과 일치하게 하는것 \n",
    "- 최초 딥러닝 모델의 매개변수(w,b)를 무작위로 부여한후, 반복학습을 통해 모델의 출력값이 최대한 정답과 일치되도록 매개변수를 조정하는 과정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순전파(forward propagation)\n",
    ": 예측값을 계산하는 과정 \n",
    "### 손실함수(Loss Fucntion)\n",
    "- 출력값과 정답의 차이 \n",
    "- 출력값이 정답에 일치할수록 손실함수의 값은 작아진다.\n",
    "- 보통 회귀에서는 평균제곱오차(Mean Squared Error: MSE)\n",
    "- 분류 문제에서는 크로스 엔트로피(Cross Entropy)를 사용 \n",
    "- 매개변수를 조절해서 손실함수의 값을 최저로 만드는 과정을 최적화(Optimization)이라 한다. \n",
    "- 최적화 과정은 Optimizer를 통해 이뤄지며 Optimizer는 역전파 과정을 수행해서 딥러닝 모델의 매개변수를 최적화 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 (Optimization)\n",
    "- 대표적인 방법은 경사 하강법(gradient descent) \n",
    "- 반복적으로 손실함수에 대한 모델 매개변수의 미분값(기울기)을 구한후 그 미분값의 반대방향으로 매개변수를 조절해 나가면 결국에서 최저 손실함수값이 도달한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파(back propagation)\n",
    "- Optimizer는 손실함수의 값을 최소화 하기 위해 역전파를 사용해 딥러닝 모델의 모든 매개변수를 변경한다. \n",
    "- 손실함수의 값을 최소화 한다는 것은 정답과 예측값의 차이를 최소화 한다는 것이며 에러율을 최저로 줄인다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "- Batch 경사 하강법 : 전체 sample을 한번에 \n",
    "- SGD(Stochastic Gradient Descent : 경사 하강법) : data를 sample별로 1개씩 \n",
    "- mini Batch 경사 하강법 : sample 갯수를 정해서 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃(Drop Out)\n",
    "- 드롭아웃은 해당 Node의 갯수를 줄이는 방법으로 과대적합을 피한다. \n",
    "- 드롭아웃을 사용하면 모델에 앙상블 효과를 준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조기종료(Early Stopping)\n",
    "- 학습횟수에 따라 검증 정확도가 꾸준히 떨어지는 시점이 발견되면 학습을 중단 "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
